---
title: "How to load data in motherduck"
---


```{r}
#| label: setup
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| include: true

library(md)
library(tidyverse)
load_all()
```



## Create a database

Later on we will show examples of how to read data from a source file, eg. csv, parquet, excel, or even a different database, directly into duckdb but for now let's assume you want to upload some data that you already have loaded in your R environment.


Before we get into that lets review quickly the three things you need to load data into a database:
-   Database name
    -   This is object that will hold your schemas, tables or views
    -   Somtimes this may be called a catalog
-   Schema name
    -   This fancy name to classify and organize your tables, functions, procedures, etc
-   Table or view name
    -   This is the name of the actual table or view that holds your data
    
To save or reference data, you need to either fully qualify the name with `database_name.schema_name.table_name` or you need to be "in" your database and schema and reference the table name.

If you uploaded data without creating a table or schema first then duckdb will assign "temp" and "main" as the default names for your database and schema respectively.

The quickest and easiest way to get data into duckdb is either use:

-   duckdb::register_duckdb()
-   md::create_or_replace_database()

The different is create_or_replace_database() gives you more control on the database name and schema name.

```{r}
#| label: create-table
#| echo: true
#| eval: true
#| warning: true
#| message: true
#| include: true



temp_con <- DBI::dbConnect(duckdb::duckdb()) #<1>

ggplot2::diamonds |>  #<2>
    create_table(
        .con = temp_con #<3>
        ,database_name = "memory" #<4>
        ,schema_name = "raw" #<5>
        ,table_name = "diamonds" #<6>
        ,write_type="overwrite"  #<7>
        )
```

1. motherduck connection with your token
2. Pass your data into the function
3. List your motherduck connection
4. database name (either new or existing)
5. schema name
6. table name
7. Either overwrite or append the data

Notice that we don't assign this object to anything, this just silently writes our data to our database, to validate the data is in our database, we can do the following:

We can validate if we have successfully saved the table in our database by running `list_tables()`

::: {.callout-note}
## Duckdb vs. Motherduck

If you have a local file or in memory duckdb connection, then you can't create a new database but this function will still work but it will just ignore the database_name you supply it and instead take the name of your current connection.

This is because a your local file / in memory connection is the database -- you can't create or replace a database on top of that. However in motherduck you can create multiple databases.

:::

```{r}
#| label: list-tables-example
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| include: true

list_all_tables(temp_con)
```

After running these functions, we can see our table - ready for us to query it. 

If you want to access your motherduck data, you can simply leverage` dplyr::tbl()` function with your motherduck connection to pull your data and from there leverage the fantastic dbplyr or dplyr package respectively to use tidy verbs to perform additional functions

## organizing our data

Let's say we want to filter and summarize this table and save to our database new name -- no problem, we can repeat the steps and this time we will upload a DBI object instead of tibble.

```{r}
#| eval: false

id_name <- DBI::Id("raw","diamonds") #<1>

diamonds_summary_tbl <- tbl(temp_con,id_name) |>  #<2>
    summarise(
        .by=c(color,cut,clarity)
        ,mean_price=mean(price,na.rm=TRUE)
    )

diamonds_summary_tbl |>
    create_table(   #<3>
    .con = temp_con
    ,database_name = "memory"
    ,schema_name = "raw"
    ,table_name = "diamonds_summary" 
    ,write_type = "overwrite"
)

```
1. x
2. y
3. z


While its the same syntax, create_table will work with an R objct or DBI object to save that table into your database. 

We can validate the tables are correctly loaded with the below function

```{r}
#| label: list-all-tables1
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| include: true
list_all_tables(temp_con)
```

## create new schema

Let's saw we want to organize these existing tables into different schema, we can do this by first creating a new schema and then moving that table or  alternatively loading a table directly with a new schema and table 


```{r}
#| label: new-schema
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| include: true

    create_schema(
        .con=temp_con
        ,database_name = "memory"
        ,schema_name = "curated"
    )
```

This will create a new schema if it doesn't exist but won't load any date.


```{r}
#| label: list-schemas
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| include: true

list_schemas(temp_con)

```
::: {.callout-note}
## default schemas
Remember as default your duckdb will create a `main` schema even if you don't save any table to it
If you are using duckdb then your database will default to "memory" or the file-path that you selected

Also note that in duckdb you can't delete main schema either
:::

We can copy one of tables to our schema with 


```{r}
tables_to_move_tbl <- list_all_tables(temp_con) |> 
    collect() |> 
    dplyr::filter(
        table_name=="diamonds_summary"
    )
```


```{r}
#| label: copy-tabl-to-location
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| include: true




md::copy_tables_to_new_location(
    .con = temp_con
    ,from_table_names = tables_to_move_tbl
    ,to_database_name = "memory"
    ,to_schema_name = "curated"
    )
```

There's a complimentary function called `create_or_repalce_schema` which will also create a schema the different is if there is already a schema with that name it will delete that schema and any tables saved under it.

```{r}
list_schemas(temp_con)
```

# how to navigate around your databases or schemas

-pwd() this will help you know where you "are" and is inspired by the linux command to print working diretory (but in this case print working database)

If you were to create a new table, or upload a new schema, etc -- it would show up here

to navigate around, you can also use a linux inspired function `cd()` which is change database. This will change your database or schema that you are "in"
-cd()
    
```{r}

pwd(temp_con)

cd(temp_con,database = "memory",schema = "curated")


```

# developer notes -- need to make database arg options

Alternative you can just alter the exiting schema of your table


This will delete your old schema and any tables under the schema and replace with a new / empty schema

## drop databaes, schemas or tables

Sometimes we need to delete databases, schemas or tables. 

Be careful when you do this as its irreversible -- there is no CTRL+Z to undo this. 

```{r}
#| label: var
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| include: true

delete_schema(temp_con,database_name = "memory",schema_name = "raw",cascade = TRUE)
```

```{r}
list_all_tables(temp_con)
```


## how to load data directly into motherduck



```{r}
#| label: read-csv
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| include: true

write.csv(mtcars,"mtcars.csv")

# cd(schema = "raw")

duckdb::duckdb_read_csv(conn = temp_con,files = "mtcars.csv",name = "mtcars")

```
for excel, parquet or httpfs file formats, we can leverage md read_excel_duckdb, read_parquet_duckdb() or read_httpfs_duckdb()

```{r}
    
openxlsx::write.xlsx(starwars,"starwars.xlsx")



read_excel_duckdb(
    .con=temp_con
    ,to_database_name = "memory"
    ,to_schema_name = "raw"
    ,to_table_name = "starwars"
    ,file_path = "starwars.xlsx"
    ,header = TRUE
)

```

We can add the following options directly to function to help with uploading the excel files. Note these are available in the documentation and via the build in datasets


developer notes
-   need to add functionality for options
-   need to add print statements
-   need to add create schema / create db if not available
-   need to design robust print statements
-   

```{r}

```
-   from parquet

```{r}

iris

arrow::write_parquet(x = iris,sink = "iris.parquet")


read_parquet_duckdb(temp_con,to_table_name = "iris",file_path =  "iris.parquet")



list_all_tables(temp_con)
```

This will install and load the parquet extension and then go through the standard workflow of creating a table (and associated database / schema if not created) for your work

-   from httpfs
-   from local database to local databse
-   from MD to local
-   from local to md


```{r}
dbExecute(temp_con, "
  CREATE VIEW test_view AS
  SELECT *
  from starwars
")


tbl(temp_con,"test_view")


dbGetQuery(temp_con,
"SELECT *
FROM duckdb_views()
WHERE view_name = 'test_view';") |>
    collect() 
    pull(sql)
```



