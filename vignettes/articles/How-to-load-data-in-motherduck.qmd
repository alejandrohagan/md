---
title: "How to load data into motherduck"
---


```{r}
#| label: setup
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| include: true

library(md)
library(tidyverse)
load_all()
old_hook <- fansi::set_knit_hooks(knitr::knit_hooks, which = c("output", "warning", "error", "message"))
options(crayon.enabled = TRUE)
```


## Introduction

Before we get into how to use the package, lets quickly review the three things you will need to load data into a database:
-   Database name (Catalog Name)
    -   This is object that will hold your schemas, tables or views
    -   Different databases have their own naming convention, in motherduck, this is called Catalog 
-   Schema name
    -   This fancy name for the location that classifies and organizes your tables, functions, procedures, etc
-   Table or view name
    -   This is the name of the actual table or view that holds your data
    -   Table is a physical table of data that persists whereas a view is a stored procedures that queries underlying tables when needed
    
To save or reference data, you need to either fully qualify the name with `database_name.schema_name.table_name` or you need to be "in" your database and schema and reference the table name.

If you uploaded data without creating a table or schema first then duckdb will assign "temp" and "main" as the default names for your database and schema respectively.

:::{#nte-md .callout-note collapse="true"}
## Teminology: Duckdb vs. Motherduck 

While not technically correct, motherduck is a cloud based deployment of motherduck where you can have multiple databases, control access / permissions, and scale compute / storage as needed

Duckdb is a essentially single database instance in your local computer where you can save the database to a file or create it in memory. 

If you have a local file or in memory duckdb connection then you are limited to one database per connection. whatever the file name you assign to your connection will be the name of the connection.

When referencing md functions, simply ignore the database_name argument.

Through out these write ups, I tend to use duckdb & motherduck interchangeably however all functions will work motherduck database but most will still work with duckdb database.

:::
## Let's upload some data

Later on we will show examples of how to read data from a source file, eg. csv, parquet, or even excel directly into motherduck without loading the data into memory but for now let's assume you want to upload some data that you already have loaded in your R environment.

First let us connect to our motherduck database. In order to connect, you will need to install and load the the motherduck extension from the community store. 

The `connect_to_motherduck()` function will take your token that is your environment file, install and load the extensions if needed and connect to your motherduck instance.


::: {#cau-con .callout-caution collapse="true"}
## connecto-to-motherduck

One limitation of the connecting to motherduck from R is that you first need to create a local motherduck instance which then allows the connection to motherduck which means you have access to both local (temporary) duckdb database and your cloud based motherduck databases. 

:::


```{r}
#| label: connect
#| echo: true
#| eval: true
#| warning: true
#| message: true
#| include: true

con_md <- connect_to_motherduck(
  motherduck_token = "MOTHERDUCK_TOKEN"  #<1>
  )
```
1. Pass your token name from your R environment file

You will get a message that prints out that actions the package took and information about your connection

We can immediately check what database, schemas or tables we have access to with the `list_all_tables()` function

```{r}
#| label: list-all
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| include: true

list_all_tables(con_md)
```

Before uploading new data, it can be helpful to check "where" you are in your database

You can do this with the `pwd()`^[Naming convention is inspired by linux commands] function that will print out the current database & schema that you are in. See @cau-con to understand why we start in a local database vs. motherduck

This would be the default location that you save your database unless you clarified a different database and schema.


```{r}
#| label: pwd
#| echo: true
#| eval: true
#| warning: true
#| message: true
#| include: true

pwd(con_md)
```
By default, you will be in your local duckdb database even though you are connected to motherduck

If we want to we can also navigate to a your motherduck database with the `cd()`command

```{r}
#| label: cd
#| echo: true
#| eval: true
#| warning: false
#| message: true
#| include: true

cd(con_md,database = "contoso")
```

For this example, we will want to create a new database and schema location to upload some existing data.  `create_table()` function will create a new database and save the table under the schema.

```{r}
#| label: create-table
#| echo: true
#| eval: true
#| warning: true
#| message: true
#| include: true

ggplot2::diamonds |>  #<1>
    create_table(
        .con = con_md #<2>
        ,database_name = "vignette" #<3>
        ,schema_name = "raw" #<4>
        ,table_name = "diamonds" #<5>
        ,write_type="overwrite"  #<6>
        )
```


1. Pass your data into the function
2. List your motherduck connection
3. database name (either new or existing)
4. schema name (either new or existing)
5. table name 
6. Either overwrite or append the data

Notice that we don't assign this object to anything, this just silently writes our data to our database and prints a message confirming the performed actions

To validate the data is in our database, we can do the following:

We can validate if we have successfully saved the table in our database by running `list_all_tables()`.


```{r}
#| label: list-tables-example
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| include: true

list_all_tables(con_md) |> 
  filter(
    table_catalog=="vignette"
  )
```

After running these functions, we can see our table is ready to be queried.

If you want to access your motherduck data, you can simply leverage` dplyr::tbl()` or `DBI::dbGetQuery()` functions with your motherduck connection to pull your data.

## organizing our data

Let's say we want to filter and summarize this table and save it to our database with a new table name -- no problem, we can repeat the steps and this time we will upload a DBI object instead of tibble.


```{r}
#| label: organize
#| echo: true
#| eval: false
#| warning: false
#| message: true
#| include: true

id_name <- DBI::Id("vignette","raw","diamonds") #<1>

diamonds_summary_tbl <- dplyr::tbl(con_md,id_name) |>  #<2>
    dplyr::summarise(
        .by=c(color,cut,clarity)
        ,mean_price=mean(price,na.rm=TRUE)
    )


diamonds_summary_tbl |> #<3>
    create_table(   
    .con = con_md
    ,database_name = "vignette"
    ,schema_name = "raw"
    ,table_name = "diamonds_summary" 
    ,write_type = "overwrite"
)
```
1. You can directly call the full name or if you are already in your database / schema you can just call the table
2. Perform your additional cleaning, transformation, or summarization steps
3. Pass the DBI object to create_table and it will still save the table!

While its the same syntax, `create_table()` will work with an R object, duckplyr or DBI object to save that table into your database. 


## Create new schema

Let's say we want to organize these existing tables into different schema, we can do this by first creating a new schema and then moving that table or alternatively loading a table directly with a new schema and table.  


```{r}
#| label: new-schema
#| echo: true
#| eval: true
#| warning: false
#| message: true
#| include: true

    create_schema(
        .con=con_md
        ,database_name = "vignette"
        ,schema_name = "curated"
    )
```

This will create a new schema if it doesn't exist but won't load any data.

```{r}
#| label: list-schemas
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| include: true



list_schemas(con_md)

```


We can copy one of tables to our schema with `copy_tables_to_new_location`


```{r}
#| label: copy-table-to-location
#| echo: true
#| eval: false
#| warning: false
#| message: true
#| include: true

md::copy_tables_to_new_location(
    .con = con_md
    ,from_table_names = "diamonds_summary"
    ,to_database_name = "vignette"
    ,to_schema_name = "raw"
    )
```

There's a complimentary function called `create_or_repalce_schema` which will also create a schema the different is if there is already a schema with that name it will delete that schema and any tables saved under it.

## drop databaes, schemas or tables

Sometimes we need to delete databases, schemas or tables. 

Be careful when you do this as its irreversible -- there is no CTRL+Z to undo this. 


```{r}
#| label: var
#| echo: true
#| eval: true
#| warning: false
#| message: true
#| include: true

delete_schema(con_md,database_name = "vignette",schema_name = "curated",cascade = TRUE)
```

```{r}
#| label: list-all-tables-1
#| echo: true
#| eval: true
#| warning: false
#| message: true
#| include: true
list_all_tables(con_md)
```

## how to load data directly into motherduck

For csv files we can leverage the existing duckdb function `duckdb::read_csv_duckdb()` to directly read the a csv file or a series of csv files^[as long as they have the same header structure] into your duckdb or motherduck database

This will read the files from their source location directly into your database without loading the files into memory which is helpful when you are dealing with larger than memory data.

Underneath the hood the duckdb function is using the `read_csv_auto` and you can pass the configuration options  directly through the the read_csv function if you need configuration.



```{r}
#| label: read-csv
#| echo: true
#| eval: true
#| warning: false
#| message: true
#| include: true

write.csv(mtcars,"mtcars.csv")

# cd(schema = "raw")

duckdb::duckdb_read_csv(conn = con_md,files = "mtcars.csv",name = "mtcars")

fs::file_delete("mtcars.csv")
```

For or excel, parquet or httpfs file formats, we can leverage md read_excel_duckdb, read_parquet_duckdb() or read_httpfs_duckdb() form the `md` package.

Similar to the `read_csv_auto` function, these leverage underlying duckdb extensions to read these diffrent file formatas.

You can view the default configuration tables with the md::config_* family of tables 



```{r}
#| label: read-xl
#| echo: true
#| eval: true
#| warning: true
#| message: true
#| include: true
    
openxlsx::write.xlsx(starwars,"starwars.xlsx") #1

# temp_con <- DBI::dbConnect(duckdb::duckdb())

read_excel_duckdb(
    .con=con_md #2
    ,to_database_name = "vignette" #3
    ,to_schema_name = "main" #4
    ,to_table_name = "starwars" #5
    ,file_path = "starwars.xlsx" #6
    ,header = TRUE #7
    ,sheet = "Sheet 1" #8
    ,all_varchar  = TRUE #9
    ,write_type = "overwrite"  #10
)

```

1. Create a excel file
2. Pass through our connection
3. Select the database we want the table to be saved in
4. Select the schema we want the table to be saved in
5. Select the table name
6. Select the filepath to the excel file  
7. Clarify if we want the first line to be used as headers
8. Clarify the sheet name to read
9. Clarify if all columns types be read in as characters
10. Select if we should overwrite to an existing table or append

Below are the list of configuration options available to be passed through to respective read_* functions.

```{r}
#| label: delete-excel
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| include: false
fs::file_delete("starwars.xlsx")
```

::: {.callout-note collapse="true"}
## Configuration options



:::{.panel-tabset}
## CSV

```{r}
#| label: config-csv
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| include: true
md::config_csv |> 
  gt::gt()

```
## Excel

```{r}
#| label: config-excel
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| include: true

md::config_excel |> 
  gt::gt()
```
## Parquet

```{r}
#| label: config-parquet
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| include: true


md::config_parquet |> 
  gt::gt()
```
:::

:::
